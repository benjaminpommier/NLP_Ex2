{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATSA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "import gzip\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import one_hot, text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from cnn_gcat import CNN_Gate_Aspect_Text\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>aspect_category</th>\n",
       "      <th>target_term</th>\n",
       "      <th>start:end</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>AMBIENCE#GENERAL</td>\n",
       "      <td>seating</td>\n",
       "      <td>18:25</td>\n",
       "      <td>short and sweet – seating is great:it's romant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>AMBIENCE#GENERAL</td>\n",
       "      <td>trattoria</td>\n",
       "      <td>25:34</td>\n",
       "      <td>This quaint and romantic trattoria is at the t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>FOOD#QUALITY</td>\n",
       "      <td>food</td>\n",
       "      <td>98:102</td>\n",
       "      <td>The have over 100 different beers to offer thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>SERVICE#GENERAL</td>\n",
       "      <td>STAFF</td>\n",
       "      <td>5:10</td>\n",
       "      <td>THIS STAFF SHOULD BE FIRED.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>FOOD#STYLE_OPTIONS</td>\n",
       "      <td>menu</td>\n",
       "      <td>4:8</td>\n",
       "      <td>The menu looked great, and the waiter was very...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity     aspect_category target_term start:end  \\\n",
       "0  positive    AMBIENCE#GENERAL     seating     18:25   \n",
       "1  positive    AMBIENCE#GENERAL   trattoria     25:34   \n",
       "2  positive        FOOD#QUALITY        food    98:102   \n",
       "3  negative     SERVICE#GENERAL       STAFF      5:10   \n",
       "4  positive  FOOD#STYLE_OPTIONS        menu       4:8   \n",
       "\n",
       "                                            sentence  \n",
       "0  short and sweet – seating is great:it's romant...  \n",
       "1  This quaint and romantic trattoria is at the t...  \n",
       "2  The have over 100 different beers to offer thi...  \n",
       "3                        THIS STAFF SHOULD BE FIRED.  \n",
       "4  The menu looked great, and the waiter was very...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data = \"./data/\"\n",
    "path_src = \"./src/\"\n",
    "\n",
    "# train set\n",
    "df_train = pd.read_csv(path_data + 'traindata.csv', sep = '\\t', header = None)\n",
    "df_train.columns = ['polarity', 'aspect_category', 'target_term', 'start:end', 'sentence']\n",
    "\n",
    "#dev set\n",
    "df_dev = pd.read_csv(path_data + 'devdata.csv', sep = '\\t', header = None)\n",
    "df_dev.columns = ['polarity', 'aspect_category', 'target_term', 'start:end', 'sentence']\n",
    "\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de y_train et y_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1503])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = torch.Tensor(df_train['polarity'].map({'positive':2, 'neutral':1, 'negative':0}).values)\n",
    "y_dev = torch.Tensor(df_dev['polarity'].map({'positive':2, 'neutral':1, 'negative':0}).values)\n",
    "\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de X_train et X_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_embedding(filepath, vocab_size):\n",
    "    assert str(filepath).endswith('.gz')\n",
    "    words = {}\n",
    "    with gzip.open(filepath, 'rt', encoding=\"utf8\") as f:  # Read compressed file directly\n",
    "        next(f)  # Skip header\n",
    "        for i, line in enumerate(f):\n",
    "            word, vec = line.split(' ', 1)\n",
    "            words[word] = np.fromstring(vec, sep=' ')\n",
    "            if i == (vocab_size - 1):\n",
    "                break\n",
    "    print('Loaded %s pretrained word vectors' % (len(words)))\n",
    "    return words\n",
    "    \n",
    "def assign_embeddings(pretrained_emb, word2idx, embed_dim=300):\n",
    "    embeddings = np.zeros((len(word2idx),embed_dim))\n",
    "    oov = 0\n",
    "    for word, index in word2idx.items():\n",
    "        try:\n",
    "            vector = np.array(pretrained_emb[word], dtype='float32')\n",
    "        except KeyError as e:\n",
    "            oov += 1\n",
    "            vector = np.random.uniform(low=-1, high=1, size=embed_dim)\n",
    "        embeddings[index] = vector\n",
    "    print('%.0f out-of-vocabulary words'%(oov))\n",
    "    return embeddings\n",
    "\n",
    "#load pre trained embedding\n",
    "PATH_TO_DATA = Path('src/')\n",
    "en_embeddings_path = PATH_TO_DATA / 'cc.en.300.vec.gz'\n",
    "if not en_embeddings_path.exists():\n",
    "    urlretrieve('https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz', en_embeddings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 100000 pretrained word vectors\n",
      "360 out-of-vocabulary words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1879, 59])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 100000\n",
    "\n",
    "sentences_train = df_train['sentence']\n",
    "sentences_dev = df_dev['sentence']\n",
    "sentences = pd.concat([sentences_train, sentences_dev])\n",
    "\n",
    "#Transform sentences in list of words\n",
    "sentences = list(sentences.apply(lambda sentence: text_to_word_sequence(sentence, lower=False)).values)\n",
    "vocab = set(itertools.chain.from_iterable(sentences))\n",
    "\n",
    "#Initialize useful dictionnary\n",
    "wrd2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx2wrd = {idx: word for idx, word in enumerate(vocab)}\n",
    "\n",
    "#one hot encoding of the sentences\n",
    "idx_transform = lambda sentence: [wrd2idx[word] for word in sentence]\n",
    "sent = [idx_transform(sent) for sent in sentences]\n",
    "\n",
    "#load the pretrained embeddings\n",
    "pretrained_emb = load_pretrained_embedding(en_embeddings_path, vocab_size)\n",
    "\n",
    "#assign the good embedding matrix\n",
    "embedding_matrix = assign_embeddings(pretrained_emb, wrd2idx, embed_dim=300)\n",
    "    \n",
    "X1 = torch.LongTensor(pad_sequences(sent))\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162 out-of-vocabulary words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1879, 15])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size_target = 2000\n",
    "\n",
    "target_train = df_train['target_term']\n",
    "target_dev = df_dev['target_term']\n",
    "targets = pd.concat([target_train, target_dev])\n",
    "\n",
    "#Transform sentences in list of words\n",
    "targets = list(targets.apply(lambda target: text_to_word_sequence(target, lower=False)).values)\n",
    "vocab_target = set(itertools.chain.from_iterable(targets))\n",
    "\n",
    "#Initialize useful dictionnary\n",
    "wrd2idx_target = {word: idx for idx, word in enumerate(vocab_target)}\n",
    "idx2wrd_target = {idx: word for idx, word in enumerate(vocab_target)}\n",
    "\n",
    "#one hot encoding of the sentences\n",
    "idx_transform_target = lambda sentence: [wrd2idx_target[word] for word in sentence]\n",
    "target = [idx_transform_target(sent) for sent in targets]\n",
    "\n",
    "#assign the good embedding matrix\n",
    "embedding_matrix_target = assign_embeddings(pretrained_emb, wrd2idx_target, embed_dim=300)\n",
    "\n",
    "X2 = torch.LongTensor(pad_sequences(target))\n",
    "X2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1503, 32])\n",
      "torch.Size([376, 32])\n"
     ]
    }
   ],
   "source": [
    "# max number for context and aspect\n",
    "max_aspect = 2\n",
    "max_context = 30\n",
    "\n",
    "# useful params\n",
    "l1 = min(X1.shape[1], max_context) # max length of a sentence\n",
    "l2 = min(X2.shape[1], max_aspect) # max length of target name\n",
    "train_size = int(X1.shape[0] * 0.8) # take 80% of data for train set and 20% for dev set\n",
    "\n",
    "# reduce dimension\n",
    "X1 = X1[:,-min(l1,max_context):]\n",
    "X2 = X2[:,-min(l2,max_aspect):]\n",
    "\n",
    "# gather tensor\n",
    "X = torch.cat([X1, X2], 1)\n",
    "\n",
    "# train set & dev set creation\n",
    "X_train = X[:train_size, :]\n",
    "X_dev = X[train_size:, :]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(X_train, y_train)\n",
    "dataset_dev = TensorDataset(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "2.0    0.701929\n",
      "0.0    0.259481\n",
      "1.0    0.038589\n",
      "dtype: float64\n",
      "\n",
      "Dev set\n",
      "2.0    0.702128\n",
      "0.0    0.260638\n",
      "1.0    0.037234\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Train set')\n",
    "print(pd.Series(y_train).value_counts(normalize = True))\n",
    "print('')\n",
    "print('Dev set')\n",
    "print(pd.Series(y_dev).value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Gate_Aspect_Text(nn.Module):\n",
    "    def __init__(self, Co=100, L=300, Ks=[3,4,5], C=3, embed_num = 20000, embed_dim = 300, aspect_embed_num = 2000,\n",
    "                 aspect_embed_dim = 300, embedding = None, aspect_embedding = None):\n",
    "        super(CNN_Gate_Aspect_Text, self).__init__()\n",
    "        #Initialize the embedding, with weights if pre-trained embedding provided\n",
    "        if embedding is None:\n",
    "            self.embed = nn.Embedding(embed_num, embed_dim)\n",
    "        else:\n",
    "            self.embed = nn.Embedding(embedding.shape[0], embedding.shape[1]) \n",
    "            self.embed.weight = nn.Parameter(torch.from_numpy(embedding).float(), requires_grad=True)\n",
    "        \n",
    "        #Initialise the embedding for the aspect, with weights if pretrained embedding provided\n",
    "        if embedding is None:\n",
    "            self.aspect_embed = nn.Embedding(aspect_embed_num, aspect_embed_dim)\n",
    "        else:\n",
    "            self.aspect_embed = nn.Embedding(aspect_embedding.shape[0], aspect_embedding.shape[1]) \n",
    "            self.aspect_embed.weight = nn.Parameter(torch.from_numpy(aspect_embedding).float(), requires_grad=True)\n",
    "            \n",
    "        self.convs1 = nn.ModuleList([nn.Conv1d(embed_dim, Co, K) for K in Ks])\n",
    "        self.convs2 = nn.ModuleList([nn.Conv1d(embed_dim, Co, K) for K in Ks])\n",
    "        self.convs3 = nn.ModuleList([nn.Conv1d(embed_dim, L, 3, padding=1)])\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        #Predict the classes\n",
    "        self.fc1 = nn.Linear(len(Ks)*Co, C)\n",
    "        self.fc_aspect = nn.Linear(L, Co)\n",
    "\n",
    "\n",
    "    def forward(self, feature, aspect):\n",
    "        #Aspect embeddings >> TO CHECK: for me, they call aspect, the term related to the aspect category\n",
    "        aspect_v = self.aspect_embed(aspect)  # (N, L', D)\n",
    "        aa = [F.relu(conv(aspect_v.transpose(1, 2))) for conv in self.convs3]  # [(N,Co,L), ...]*len(Ks)\n",
    "        aa = [F.max_pool1d(a, a.size(2)).squeeze(2) for a in aa]\n",
    "        aspect_v = torch.cat(aa, 1) #Check what is it ? Not needed here\n",
    "\n",
    "        #Embedding of the context\n",
    "        feature = self.embed(feature)  # (N, L, D)\n",
    "        x = [torch.tanh(conv(feature.transpose(1, 2))) for conv in self.convs1]  # [(N,Co,L), ...]*len(Ks)\n",
    "        y = [torch.relu(conv(feature.transpose(1, 2)) + self.fc_aspect(aspect_v).unsqueeze(2)) for conv in self.convs2]\n",
    "        x = [i*j for i, j in zip(x, y)]\n",
    "        # pooling method\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N,Co), ...]*len(Ks)\n",
    "\n",
    "        x = torch.cat(x, 1) #Check what is it ?\n",
    "        x = self.dropout(x)  # (N,len(Ks)*Co)\n",
    "        logit = self.fc1(x)  # (N,C)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## def train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model: \n",
    "# model = CNN_Gate_Aspect_Text()\n",
    "model = CNN_Gate_Aspect_Text(embedding=embedding_matrix, aspect_embedding=embedding_matrix_target)\n",
    "\n",
    "# Hyperparameters for training: \n",
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-0, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy to evaluate the model\n",
    "def accuracy(dataset, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        dataloader = DataLoader(dataset)\n",
    "        for X, labels in dataloader:\n",
    "            outputs = model(X[:, :l1], X[:, -l2:])\n",
    "            _, predicted = torch.max(outputs.data, 1) \n",
    "            correct += (predicted == labels).sum()\n",
    "\n",
    "    return 100*correct.item()/ len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function for training\n",
    "def train(model, dataset_train, dataset_dev, num_epochs, batch_size, criterion, optimizer):\n",
    "    t = time()\n",
    "    train_loader = DataLoader(dataset_train, batch_size, shuffle=True)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        acc = 0.\n",
    "        for (X_batch, labels) in train_loader:\n",
    "            y_pre = model(X_batch[:, :l1], X_batch[:, -l2:])\n",
    "            loss = criterion(y_pre, labels.long())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, predicted = torch.max(y_pre.data, 1) \n",
    "            acc += (predicted == labels).sum().item()\n",
    "        \n",
    "        acc = 100 * acc / len(dataset_train)\n",
    "        dev_acc = accuracy(dataset_dev, model)\n",
    "        print('Epoch [{}/{}] | exec time: {:.2f} secs | acc: {:.2f}% | dev_acc: {:.2f}%'.format(epoch+1, num_epochs, time()-t, acc, dev_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] | exec time: 44.63 secs | acc: 58.08% | dev_acc: 65.96%\n",
      "Epoch [2/10] | exec time: 105.86 secs | acc: 65.20% | dev_acc: 69.41%\n",
      "Epoch [3/10] | exec time: 166.68 secs | acc: 63.74% | dev_acc: 71.01%\n",
      "Epoch [4/10] | exec time: 228.33 secs | acc: 63.14% | dev_acc: 70.74%\n",
      "Epoch [5/10] | exec time: 298.67 secs | acc: 65.74% | dev_acc: 71.54%\n",
      "Epoch [6/10] | exec time: 359.94 secs | acc: 64.47% | dev_acc: 70.48%\n",
      "Epoch [7/10] | exec time: 421.52 secs | acc: 66.40% | dev_acc: 70.74%\n",
      "Epoch [8/10] | exec time: 484.00 secs | acc: 65.27% | dev_acc: 32.18%\n",
      "Epoch [9/10] | exec time: 552.31 secs | acc: 60.08% | dev_acc: 70.48%\n",
      "Epoch [10/10] | exec time: 616.25 secs | acc: 63.07% | dev_acc: 32.45%\n"
     ]
    }
   ],
   "source": [
    "train(model, dataset_train, dataset_dev, num_epochs, batch_size, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def report(dataset, model):\n",
    "    predicted_all = []\n",
    "    labels_all = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        dataloader = DataLoader(dataset)\n",
    "        for X, labels in dataloader:\n",
    "            outputs = model(X[:, :l1], X[:, -l2:])\n",
    "            _, predicted = torch.max(outputs.data, 1) \n",
    "            correct += (predicted == labels).sum()\n",
    "            predicted_all.append(int(predicted[0]))\n",
    "            labels_all.append(int(labels[0]))\n",
    "\n",
    "    print(classification_report(labels_all,predicted_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for dev set is : 73.94 %\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.16      0.27        98\n",
      "           1       0.00      0.00      0.00        14\n",
      "           2       0.74      0.99      0.85       264\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       376\n",
      "   macro avg       0.51      0.39      0.37       376\n",
      "weighted avg       0.73      0.74      0.66       376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dev set\n",
    "accuracy_dev = accuracy(dataset_dev, model)\n",
    "print('Accuracy for dev set is : {:.2f} %'.format(accuracy_dev))\n",
    "print('')\n",
    "report(dataset_dev, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for train set is : 78.98 %\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.35      0.51       390\n",
      "           1       0.00      0.00      0.00        58\n",
      "           2       0.77      1.00      0.87      1055\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1503\n",
      "   macro avg       0.57      0.45      0.46      1503\n",
      "weighted avg       0.79      0.79      0.74      1503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "accuracy_train = accuracy(dataset_train, model)\n",
    "print('Accuracy for train set is : {:.2f} %'.format(accuracy_train))\n",
    "print('')\n",
    "report(dataset_train, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
